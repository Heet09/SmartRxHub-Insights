  Project Evolution: SmartRxHub-Insights Documentation

  Objective: To transform the "SmartRxHub-Insights" project from a static, batch-processing tool into a dynamic, real-time, AI-powered risk prediction system with a fully automated CI/CD pipeline.

  ---

  Phase 1: Foundational Shift - Real-time Data Ingestion

  Goal: Transition the system from processing a static CSV file to ingesting data from a live API endpoint.

   1. API Scaffolding:
       * Action: A new api directory was created to house the real-time components.
       * Action: A main.py file was created within the api directory using the FastAPI framework to define a simple /ingest endpoint.
       * Action: requirements.txt was updated to include fastapi and uvicorn (the server needed to run the API).

   2. Data Simulation:
       * Action: A scripts/data_simulator.py script was created to mimic a live eMAR data feed by sending randomly generated data to the /ingest endpoint every few seconds.

   3. Execution and Debugging:
       * Challenge: The initial command to run the server (uvicorn api.main:app --host 0.0.0.0 --port 8000 &) caused the system to hang.
       * Error Analysis: The command was intended to run as a background process, but the execution environment was waiting for the command to "complete." A server process, by design, never completes; it runs continuously. This
         prevented any further commands from being executed.
       * Solution: The command was modified to be compatible with the Windows environment by using start /B. This command correctly starts the process in the background without tying up the command line. The final, successful command
         was:
   1         start /B uvicorn api.main:app --host 0.0.0.0 --port 8000 > server.log 2>&1

   4. Verification:
       * Result: With the server running correctly in the background, the data_simulator.py script was also started. By inspecting the server.log file, we confirmed that the API was receiving POST requests and logging the incoming data,
          successfully completing Phase 1.

  ---

  Phase 2: Intelligence Layer - Predictive AI

  Goal: Integrate a machine learning model to analyze incoming data and predict medication risk in real-time.

   1. Model Creation:
       * Action: A new ml directory was created for machine learning assets.
       * Action: A trainer.py script was developed using scikit-learn to train a RandomForestClassifier on a sample dataset.
       * Action: Upon execution, the script saved the trained model to ml/emar_risk_model.joblib.

   2. API Integration:
       * Action: The api/main.py script was updated to load the emar_risk_model.joblib file at startup.
       * Action: The /ingest endpoint logic was enhanced to use the loaded model to generate a "High" or "Low" risk prediction for each incoming data point.

   3. Verification:
       * Result: After restarting the API server, the server.log file was inspected again. The logs now included the model's output (e.g., Predicted Risk: Low), confirming that the AI integration was successful.

  ---

  Phase 3: Automation & Robustness - CI/CD & MLOps

  Goal: Automate the testing and training pipeline using GitHub Actions.

   1. Workflow Enhancement:
       * Action: The .github/workflows/emar_risk_engine.yml file was updated.
       * Action: A linting step using ruff was added to ensure code quality.
       * Action: The workflow was configured to automatically run the ml/trainer.py script and upload the resulting emar_risk_model.joblib file as a versioned build artifact. This ensures the model is always up-to-date with the latest
         code.

  ---

  Phase 4: Dashboard Upgrade

  Goal: Connect the Streamlit dashboard to the new real-time, AI-powered API.

   1. Dashboard Refactoring:
       * Action: The dashboard/streamlit_dashboard.py script was completely rewritten. Instead of reading a CSV, it now enters a loop that continuously calls the /ingest API endpoint to get new data and a risk prediction.
       * Action: The UI was designed to show a live log of all events and a separate, prominent section for "High-Risk Events."

   2. Execution and Debugging:
       * Error 1: AttributeError: module 'pandas' has no attribute 'np'.
       * Analysis: The code was using pd.np, a deprecated syntax from older versions of the pandas library.
       * Solution: The script was corrected by adding import numpy as np and changing all instances of pd.np to np.

       * Error 2: requests.exceptions.ConnectionError: ...target machine actively refused it.
       * Analysis: This error indicated that the dashboard could not connect to the API. We realized the API server was not running at that moment.
       * Solution: The API server was restarted using the start /B command.

   3. Final Result:
       * With the API server running, the Streamlit dashboard was launched successfully. It immediately began populating with live data, displaying real-time medication events and their corresponding AI-generated risk levels, fulfilling
          the final phase of the project.
